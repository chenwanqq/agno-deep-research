本报告系统梳理了深度学习发展的两大关键阶段及其里程碑式突破，揭示了从理论奠基到实践革命的完整演进脉络。

第一阶段（1943–1986年）为理论奠基期：McCulloch-Pitts神经元模型构建了计算框架，Rosenblatt感知机首次实现权重自适应学习，但受限于单层结构无法处理非线性问题，导致领域陷入低谷。1986年反向传播算法的提出，首次实现了多层网络的有效训练，为深度学习奠定了核心方法论基础，却因算力与数据不足未能立即推广。

第二阶段（2006–2012年）为复兴期：Hinton等人提出的深度信念网络（DBN）与堆叠自动编码器（SAE），通过“无监督预训练+有监督微调”范式，成功破解深层网络训练中的梯度消失与初始化难题，利用未标注数据预训练获得高质量初始参数，首次实证“深度”的有效性，重新点燃学术界信心，直接催化了2012年AlexNet的爆发。

2012–2015年，CNN在ImageNet竞赛中的连续突破标志着深度学习全面崛起。AlexNet以ReLU、Dropout和GPU并行训练实现历史性性能跃升，终结传统特征工程；VGGNet通过堆叠3×3小卷积核验证了深度架构的优越性，成为通用特征提取标准；GoogLeNet创新性引入Inception模块，以1×1卷积降维实现效率与精度的平衡，推动网络设计从“堆层数”转向“智能结构优化”。三者共同确立“端到端学习”范式，无需人工特征工程即可自动学习最优表征，不仅重塑计算机视觉领域，更引爆全球AI研究热潮，加速人工智能从学术探索迈向大规模产业应用，奠定现代AI的技术基石。