from agno.agent import Agent
from agno.workflow.v2 import Workflow
from agno.memory.v2 import Memory
from agno.exceptions import StopAgentRun
from agno.tools import FunctionCall, tool
from rich.console import Console
from rich.pretty import pprint
from rich.prompt import Prompt, Confirm
from rich.panel import Panel
from rich.markdown import Markdown
from pydantic import BaseModel, Field
from typing import Dict, Any, List, Optional
import sys
import os
import json

# å¯¼å…¥utilsæ¨¡å—
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'utils'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'custom_tools'))
from model_config import create_reasoning_model, create_small_instruct_model
from prompt_loader import load_prompt_template, get_agent_params
from custom_tools.tavily_tools_with_index import TavilyToolsWithIndex

# æ§åˆ¶å°å®ä¾‹
console = Console()

class ResearchPlan(BaseModel):
    """ç ”ç©¶è®¡åˆ’æ•°æ®æ¨¡å‹"""
    title: str = Field(..., description="ç ”ç©¶è®¡åˆ’æ ‡é¢˜")
    overview: str = Field(..., description="ç ”ç©¶è®¡åˆ’æ¦‚è¿°")
    subtasks: List[Dict[str, str]] = Field(..., description="å­ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªå­ä»»åŠ¡åŒ…å«description, expected_output, importance")

class FeedbackEvaluation(BaseModel):
    """ç”¨æˆ·åé¦ˆè¯„ä¼°ç»“æœ"""
    action: str = Field(..., description="ä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼šconfirm, modify, regenerate")
    is_satisfied: bool = Field(..., description="ç”¨æˆ·æ˜¯å¦æ»¡æ„å½“å‰è®¡åˆ’")
    modification_suggestions: Optional[str] = Field(None, description="ä¿®æ”¹å»ºè®®")
    reason: Optional[str] = Field(None, description="è¯„ä¼°åŸå› ")

def approval_hook(fc: FunctionCall):
    """æ“ä½œç¡®è®¤é’©å­å‡½æ•°"""
    live = console._live_stack[-1]
    if live:
        live.stop()
    
    console.print(f"\n[bold blue]å³å°†æ‰§è¡Œ: {fc.function.name}[/]")
    if not Confirm.ask("æ˜¯å¦ç»§ç»­æ‰§è¡Œæ­¤æ“ä½œ?", default=True):
        if live:
            live.start()
        raise StopAgentRun(
            "æ“ä½œè¢«ç”¨æˆ·å–æ¶ˆ",
            agent_message="æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œæˆ‘å·²åœæ­¢æ‰§è¡Œæ­¤æ“ä½œã€‚"
        )
    
    if live:
        live.start()

@tool(pre_hook=approval_hook)
def search_background_info(query: str) -> str:
    """æœç´¢èƒŒæ™¯ä¿¡æ¯ä»¥è¾…åŠ©åˆ¶å®šç ”ç©¶è®¡åˆ’
    
    Args:
        query (str): æœç´¢æŸ¥è¯¢å…³é”®è¯
        
    Returns:
        str: æœç´¢ç»“æœçš„JSONå­—ç¬¦ä¸²
    """
    tavily_tools = TavilyToolsWithIndex(include_answer=False, format='json')
    result = tavily_tools.web_search_using_tavily(query)
    return json.dumps({
        "search_query": query,
        "search_result": result
    }, ensure_ascii=False)

def generate_research_plan(message: str) -> Dict[str, Any]:
    """æ­¥éª¤1: ç”Ÿæˆç ”ç©¶è®¡åˆ’"""
    console.print("\n[dim]æ­£åœ¨ç”Ÿæˆç ”ç©¶è®¡åˆ’...[/]")
    plan_gen_template = load_prompt_template('plan_generator_agent')
    plan_gen_params = get_agent_params(plan_gen_template)
    
    plan_generator = Agent(
        #model=create_reasoning_model(),
        model=create_small_instruct_model(),
        tools=[search_background_info],
        add_datetime_to_instructions=True,
        response_model=ResearchPlan,
        use_json_mode=True,
        **plan_gen_params
    )
    
    response = plan_generator.run(message)
    plan_data = response.content
    
    try:
        if isinstance(plan_data, str):
            plan = json.loads(plan_data)
        else:
            plan = plan_data.model_dump() if hasattr(plan_data, 'model_dump') else plan_data
        return plan
    except (json.JSONDecodeError, AttributeError) as e:
        console.print(f"[red]è®¡åˆ’æ ¼å¼é”™è¯¯: {str(e)}[/]")
        raise ValueError(f"è®¡åˆ’æ ¼å¼é”™è¯¯: {str(e)}")

def display_plan_and_get_feedback(plan: Dict[str, Any]) -> tuple[str, str]:
    """æ­¥éª¤2: å±•ç¤ºè®¡åˆ’å¹¶æ”¶é›†ç”¨æˆ·åé¦ˆ"""
    console.print("\n[dim]æ­£åœ¨å±•ç¤ºç ”ç©¶è®¡åˆ’...[/]")
    
    # è·å–live displayå®ä¾‹å¹¶æš‚åœ
    live = console._live_stack[-1]
    if live:
        live.stop()
    
    # å±•ç¤ºç ”ç©¶è®¡åˆ’
    console.print("\n" + "="*60)
    console.print(Panel.fit(
        f"[bold green]{plan.get('title', 'ç ”ç©¶è®¡åˆ’')}[/]",
        border_style="green"
    ))
    
    console.print(f"\n[bold]æ¦‚è¿°:[/] {plan.get('overview', '')}")
    console.print(f"[bold]é¢„ä¼°æ—¶é—´:[/] {plan.get('estimated_duration', '')}")
    
    console.print("\n[bold]ç ”ç©¶å­ä»»åŠ¡:[/]")
    subtasks = plan.get('subtasks', [])
    for i, task in enumerate(subtasks, 1):
        console.print(f"\n[bold cyan]{i}. {task.get('description', '')}[/]")
        console.print(f"   [dim]é¢„æœŸäº§å‡º:[/] {task.get('expected_output', '')}")
        console.print(f"   [dim]é‡è¦æ€§:[/] {task.get('importance', '')}")
    
    console.print("\n" + "="*60)
    
    # è·å–ç”¨æˆ·åé¦ˆ
    feedback_options = [
        "æ»¡æ„ï¼Œç¡®è®¤æ­¤è®¡åˆ’",
        "éœ€è¦ä¿®æ”¹",
        "é‡æ–°åˆ¶å®šè®¡åˆ’"
    ]
    
    console.print("\n[bold]è¯·é€‰æ‹©æ‚¨çš„åé¦ˆ:[/]")
    for i, option in enumerate(feedback_options, 1):
        console.print(f"  {i}. {option}")
    
    while True:
        try:
            choice = Prompt.ask("è¯·è¾“å…¥é€‰é¡¹ç¼–å· (1-3)", choices=["1", "2", "3"])
            break
        except KeyboardInterrupt:
            choice = "3"
            break
    
    feedback = feedback_options[int(choice) - 1]
    
    # å¦‚æœéœ€è¦ä¿®æ”¹ï¼Œè·å–å…·ä½“ä¿®æ”¹æ„è§
    modification_details = ""
    if choice == "2":
        modification_details = Prompt.ask("\nè¯·è¯¦ç»†è¯´æ˜æ‚¨å¸Œæœ›å¦‚ä½•ä¿®æ”¹è¿™ä¸ªè®¡åˆ’")
    
    # é‡å¯live display
    if live:
        live.start()
    
    return choice, modification_details

def process_user_feedback(choice: str, modification_details: str, original_message: str) -> tuple[str, str]:
    """æ­¥éª¤3: å¤„ç†ç”¨æˆ·åé¦ˆ"""
    if choice == "1":  # ç”¨æˆ·æ»¡æ„
        return "confirmed", original_message
    elif choice == "2":  # éœ€è¦ä¿®æ”¹
        console.print("\n[dim]æ­£åœ¨è¯„ä¼°ä¿®æ”¹å»ºè®®...[/]")
        # å°†ä¿®æ”¹å»ºè®®åŠ å…¥åˆ°åŸå§‹æ¶ˆæ¯ä¸­ï¼Œé‡æ–°ç”Ÿæˆ
        new_message = f"åŸå§‹é—®é¢˜: {original_message}\n\nç”¨æˆ·ä¿®æ”¹å»ºè®®: {modification_details}\n\nè¯·æ ¹æ®ç”¨æˆ·çš„ä¿®æ”¹å»ºè®®é‡æ–°åˆ¶å®šç ”ç©¶è®¡åˆ’ã€‚"
        return "modify", new_message
    else:  # é‡æ–°åˆ¶å®šè®¡åˆ’
        console.print("\n[dim]æ­£åœ¨é‡æ–°åˆ¶å®šè®¡åˆ’...[/]")
        return "regenerate", original_message

def output_final_plan(plan: Dict[str, Any]) -> str:
    """æ­¥éª¤4: è¾“å‡ºæœ€ç»ˆç¡®è®¤çš„è®¡åˆ’"""
    live = console._live_stack[-1]
    if live:
        live.stop()
    
    console.print("\n" + "ğŸ‰" * 20)
    console.print(Panel.fit(
        "[bold green]ç ”ç©¶è®¡åˆ’å·²ç¡®è®¤ï¼[/]",
        border_style="green"
    ))
    
    # ä»¥ç»“æ„åŒ–æ ¼å¼è¾“å‡ºæœ€ç»ˆè®¡åˆ’
    console.print("\n[bold]æœ€ç»ˆç¡®è®¤çš„ç ”ç©¶è®¡åˆ’:[/]")
    final_plan_json = json.dumps(plan, ensure_ascii=False, indent=2)
    console.print(final_plan_json)
    
    if live:
        live.start()
    
    return json.dumps({
        "status": "confirmed",
        "final_plan": plan
    }, ensure_ascii=False)

def planning_workflow_function(workflow: Workflow, execution_input) -> str:
    """é‡æ„åçš„è§„åˆ’å·¥ä½œæµå‡½æ•°ï¼Œè°ƒç”¨å„ä¸ªæ­¥éª¤å‡½æ•°"""
    message = execution_input.message if hasattr(execution_input, 'message') else str(execution_input)
    original_message = message  # ä¿å­˜åŸå§‹æ¶ˆæ¯
    
    while True:
        try:
            # æ­¥éª¤1: ç”Ÿæˆç ”ç©¶è®¡åˆ’
            plan = generate_research_plan(message)
            
            # æ­¥éª¤2: å±•ç¤ºè®¡åˆ’å¹¶æ”¶é›†ç”¨æˆ·åé¦ˆ
            choice, modification_details = display_plan_and_get_feedback(plan)
            
            # æ­¥éª¤3: å¤„ç†ç”¨æˆ·åé¦ˆ
            action, updated_message = process_user_feedback(choice, modification_details, original_message)
            
            if action == "confirmed":
                # æ­¥éª¤4: è¾“å‡ºæœ€ç»ˆç¡®è®¤çš„è®¡åˆ’
                return output_final_plan(plan)
            elif action == "modify":
                message = updated_message
                continue
            else:  # regenerate
                message = original_message
                continue
                
        except Exception as e:
            console.print(f"[red]å·¥ä½œæµæ‰§è¡Œå‡ºé”™: {str(e)}[/]")
            return json.dumps({
                "status": "error",
                "error": str(e)
            }, ensure_ascii=False)

def create_planning_workflow() -> Workflow:
    """åˆ›å»ºåŸºäºçº¯Pythonå‡½æ•°çš„è§„åˆ’å·¥ä½œæµ"""
    workflow = Workflow(
        name="Planning Workflow v2.1",
        steps=planning_workflow_function  # ä½¿ç”¨å•ä¸€Pythonå‡½æ•°æ›¿ä»£æ‰€æœ‰æ­¥éª¤
    )
    
    return workflow

def run_planning_agent() -> None:
    """è¿è¡Œè§„åˆ’agentå·¥ä½œæµ"""
    console.print(Panel.fit(
        "[bold green]Deep Research Planning Agent v2.0[/]\n" +
        "é‡æ„ç‰ˆæœ¬ï¼šè§„åˆ’ç”Ÿæˆ -> è®¡åˆ’å±•ç¤º -> ç”¨æˆ·åé¦ˆ -> ç»“æ„åŒ–è¾“å‡º",
        border_style="green"
    ))
    console.print("\nè¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºç¨‹åºã€‚")
    console.print("="*50)
    
    workflow = create_planning_workflow()
    
    while True:
        try:
            message = Prompt.ask("\n[bold cyan]è¯·è¾“å…¥æ‚¨çš„ç ”ç©¶é—®é¢˜[/]")
        except (KeyboardInterrupt, EOFError):
            break
        
        if message.lower() in ["exit", "quit"]:
            break
        
        if not message.strip():
            continue
        
        console.print("\n[dim]æ­£åœ¨å¯åŠ¨è§„åˆ’å·¥ä½œæµ...[/]")
        console.print("-" * 30)
        
        try:
            workflow.print_response(message, stream=True, console=console)
        except Exception as e:
            console.print(f"[red]å¤„ç†è¯·æ±‚æ—¶å‡ºç°é”™è¯¯: {str(e)}[/]")
    
    console.print("\n[green]æ„Ÿè°¢ä½¿ç”¨Deep Research Planning Agentï¼[/]")

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæœ‰çš„å‡½æ•°
def create_planning_agent() -> Agent:
    """åˆ›å»ºè§„åˆ’agentï¼ˆå‘åå…¼å®¹ï¼‰"""
    console.print("[yellow]è­¦å‘Š: create_planning_agentå·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨create_planning_workflow[/]")
    return None

if __name__ == "__main__":
    import asyncio
    asyncio.run(run_planning_agent())